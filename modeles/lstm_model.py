"""
Mod√®le LSTM pour la pr√©diction de s√©ries temporelles
Version corrig√©e - Erreur joblib r√©solue
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import joblib  # IMPORT GLOBAL
import json
import os
from datetime import datetime, timedelta

def load_prepared_data():
    """Charge les donn√©es pr√©par√©es pour LSTM"""
    print("üìÇ Chargement des donn√©es pour LSTM...")
    
    # V√©rifier si les fichiers existent
    base_files = ['data/processed/X_seq.npy', 'data/processed/y_seq.npy']
    for file in base_files:
        if not os.path.exists(file):
            raise FileNotFoundError(f"Fichier manquant: {file}")
    
    # Charger les donn√©es de base
    X_seq = np.load('data/processed/X_seq.npy')
    y_seq = np.load('data/processed/y_seq.npy')
    
    # Liste des fichiers optionnels
    optional_files = {
        'X_val': 'data/processed/X_val_seq.npy',
        'y_val': 'data/processed/y_val_seq.npy',
        'X_test': 'data/processed/X_test_seq.npy',
        'y_test': 'data/processed/y_test_seq.npy'
    }
    
    # Initialiser les variables
    X_val_seq, y_val_seq, X_test_seq, y_test_seq = [], [], [], []
    
    # Charger les fichiers seulement s'ils existent
    for name, filepath in optional_files.items():
        if os.path.exists(filepath):
            data = np.load(filepath)
            print(f"  ‚úÖ Charg√©: {filepath} ({data.shape})")
            
            if name == 'X_val':
                X_val_seq = data
            elif name == 'y_val':
                y_val_seq = data
            elif name == 'X_test':
                X_test_seq = data
            elif name == 'y_test':
                y_test_seq = data
        else:
            print(f"  ‚ö†Ô∏è Fichier non trouv√©: {filepath}")
    
    # Forcer types num√©riques compatibles avec TensorFlow
    X_seq = X_seq.astype(np.float32)
    
    if len(X_val_seq) > 0:
        X_val_seq = X_val_seq.astype(np.float32)
    else:
        X_val_seq = np.array([], dtype=np.float32)
    
    if len(X_test_seq) > 0:
        X_test_seq = X_test_seq.astype(np.float32)
    else:
        X_test_seq = np.array([], dtype=np.float32)
    
    # y doit √™tre float32 et shape (n, 1) pour la r√©gression
    y_seq_raw = y_seq.astype(np.float32)
    y_val_raw = y_val_seq.astype(np.float32) if len(y_val_seq) > 0 else np.array([], dtype=np.float32)
    y_test_raw = y_test_seq.astype(np.float32) if len(y_test_seq) > 0 else np.array([], dtype=np.float32)
    
    # Supprimer √©chantillons contenant des NaN
    def filter_nan(X, y, name):
        if len(X) == 0:
            return X, np.array([])
        
        y_flat = np.asarray(y).reshape(-1)
        mask_nan = np.isnan(X).any(axis=(1,2)) | np.isnan(y_flat)
        if mask_nan.any():
            keep = ~mask_nan
            removed = mask_nan.sum()
            print(f"  ‚ö†Ô∏è {removed} √©chantillons contenant NaN dans {name} ont √©t√© supprim√©s.")
            X = X[keep]
            y_flat = y_flat[keep]
        return X, y_flat
    
    X_seq, y_seq_flat = filter_nan(X_seq, y_seq_raw, 'train')
    X_val_seq, y_val_flat = filter_nan(X_val_seq, y_val_raw, 'val')
    X_test_seq, y_test_flat = filter_nan(X_test_seq, y_test_raw, 'test')
    
    # Reshape targets en (n, 1)
    y_seq = y_seq_flat.astype(np.float32).reshape(-1, 1) if len(y_seq_flat) > 0 else np.array([])
    y_val_seq = y_val_flat.astype(np.float32).reshape(-1, 1) if len(y_val_flat) > 0 else np.array([])
    y_test_seq = y_test_flat.astype(np.float32).reshape(-1, 1) if len(y_test_flat) > 0 else np.array([])
    
    print(f"\nüìä R√©sum√© des dimensions:")
    print(f"  X_seq: {X_seq.shape} (entra√Ænement)")
    print(f"  y_seq: {y_seq.shape} (entra√Ænement)")
    print(f"  X_val_seq: {X_val_seq.shape} (validation)")
    print(f"  y_val_seq: {y_val_seq.shape} (validation)")
    print(f"  X_test_seq: {X_test_seq.shape} (test)")
    print(f"  y_test_seq: {y_test_seq.shape} (test)")
    
    # Si pas de donn√©es de test, cr√©er un petit ensemble √† partir des donn√©es de validation
    if len(X_test_seq) == 0 and len(X_val_seq) > 0:
        print("\n‚ö†Ô∏è Pas de donn√©es de test disponibles.")
        print("Cr√©ation d'un ensemble de test √† partir des donn√©es de validation...")
        
        # Prendre les 20% derniers √©chantillons de validation pour le test
        split_idx = int(len(X_val_seq) * 0.8)
        
        X_test_seq = X_val_seq[split_idx:]
        y_test_seq = y_val_seq[split_idx:]
        
        X_val_seq = X_val_seq[:split_idx]
        y_val_seq = y_val_seq[:split_idx]
        
        print(f"  Donn√©es de validation divis√©es:")
        print(f"    Validation: {X_val_seq.shape}")
        print(f"    Test: {X_test_seq.shape}")
    
    # Si toujours pas de test, cr√©er √† partir des donn√©es d'entra√Ænement
    if len(X_test_seq) == 0 and len(X_seq) > 10:
        print("Cr√©ation d'un ensemble de test √† partir des donn√©es d'entra√Ænement...")
        
        # Prendre les 10% derniers √©chantillons pour le test
        split_idx = int(len(X_seq) * 0.9)
        
        X_test_seq = X_seq[split_idx:]
        y_test_seq = y_seq[split_idx:]
        
        X_seq = X_seq[:split_idx]
        y_seq = y_seq[:split_idx]
        
        print(f"  Donn√©es d'entra√Ænement divis√©es:")
        print(f"    Entra√Ænement: {X_seq.shape}")
        print(f"    Test: {X_test_seq.shape}")
    
    return X_seq, y_seq, X_val_seq, y_val_seq, X_test_seq, y_test_seq

def build_lstm_model(input_shape, units=64, dropout_rate=0.2):
    """
    Construit un mod√®le LSTM
    """
    print("\nüèóÔ∏è Construction du mod√®le LSTM...")
    
    model = Sequential([
        # Premi√®re couche LSTM avec retour des s√©quences
        LSTM(units=units, return_sequences=True, input_shape=input_shape,
             kernel_initializer='he_normal'),
        Dropout(dropout_rate),
        
        # Deuxi√®me couche LSTM
        LSTM(units=units//2, return_sequences=False,
             kernel_initializer='he_normal'),
        Dropout(dropout_rate),
        
        # Couches Dense
        Dense(units=32, activation='relu', kernel_initializer='he_normal'),
        Dropout(dropout_rate/2),
        
        Dense(units=16, activation='relu', kernel_initializer='he_normal'),
        
        # Couche de sortie
        Dense(1, activation='linear')
    ])
    
    # Compilation
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='mse',
        metrics=['mae', 'mape']
    )
    
    model.summary()
    
    return model

def train_lstm_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):
    """
    Entra√Æne le mod√®le LSTM
    """
    print("\nü§ñ Entra√Ænement du mod√®le LSTM...")
    
    # D√©tecter si on a un jeu de validation non vide
    has_val = X_val is not None and len(X_val) > 0 and y_val is not None and len(y_val) > 0
    monitor_target = 'val_loss' if has_val else 'loss'
    
    # Cr√©er le dossier models si n√©cessaire
    os.makedirs('models', exist_ok=True)
    
    # D√©finir le chemin pour le meilleur mod√®le
    best_model_path = 'models/lstm_best_model.keras'
    
    # Callbacks adapt√©s selon pr√©sence ou non de validation
    callbacks = [
        EarlyStopping(
            monitor=monitor_target,
            patience=20,
            restore_best_weights=True,
            verbose=1
        ),
        ModelCheckpoint(
            filepath=best_model_path,
            monitor=monitor_target,
            save_best_only=True,
            save_weights_only=False,
            mode='min',
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor=monitor_target,
            factor=0.5,
            patience=10,
            min_lr=0.00001,
            verbose=1
        )
    ]
    
    # Entra√Ænement : utiliser validation_data seulement si fourni, sinon validation_split
    fit_kwargs = dict(
        x=X_train, y=y_train,
        epochs=epochs,
        batch_size=batch_size,
        callbacks=callbacks,
        verbose=1
    )
    
    if has_val:
        print(f"‚úÖ Utilisation de donn√©es de validation ({len(X_val)} √©chantillons)")
        fit_kwargs['validation_data'] = (X_val, y_val)
    else:
        print("‚ö†Ô∏è Pas de donn√©es de validation - utilisation d'un split interne (10%)")
        fit_kwargs['validation_split'] = 0.1

    history = model.fit(**fit_kwargs)
    
    # Sauvegarder le dernier mod√®le pour r√©f√©rence
    model.save('models/lstm_final_model.keras')
    print(f"‚úÖ Dernier mod√®le sauvegard√©: models/lstm_final_model.keras")
    
    # V√©rifier si le meilleur mod√®le a √©t√© sauvegard√©
    if os.path.exists(best_model_path):
        print(f"‚úÖ Meilleur mod√®le sauvegard√©: {best_model_path}")
    else:
        print(f"‚ö†Ô∏è Le meilleur mod√®le n'a pas √©t√© sauvegard√©")
    
    return history, model

def plot_training_history(history):
    """Visualise l'historique d'entra√Ænement"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    hist = history.history

    # Loss
    ax1 = axes[0, 0]
    ax1.plot(hist.get('loss', []), label='Train Loss', linewidth=2)
    if 'val_loss' in hist:
        ax1.plot(hist.get('val_loss', []), label='Val Loss', linewidth=2)
    ax1.set_xlabel('Epochs')
    ax1.set_ylabel('Loss (MSE)')
    ax1.set_title('√âvolution de la Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # MAE
    ax2 = axes[0, 1]
    if 'mae' in hist:
        ax2.plot(hist.get('mae', []), label='Train MAE', linewidth=2)
    if 'val_mae' in hist:
        ax2.plot(hist.get('val_mae', []), label='Val MAE', linewidth=2)
    ax2.set_xlabel('Epochs')
    ax2.set_ylabel('MAE')
    ax2.set_title('√âvolution du MAE')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # MAPE
    ax3 = axes[1, 0]
    if 'mape' in hist:
        ax3.plot(hist.get('mape', []), label='Train MAPE', linewidth=2)
    if 'val_mape' in hist:
        ax3.plot(hist.get('val_mape', []), label='Val MAPE', linewidth=2)
    ax3.set_xlabel('Epochs')
    ax3.set_ylabel('MAPE (%)')
    ax3.set_title('√âvolution du MAPE')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Learning Rate
    ax4 = axes[1, 1]
    if 'lr' in hist:
        ax4.semilogy(hist.get('lr', []), label='Learning Rate', linewidth=2)
        ax4.set_xlabel('Epochs')
        ax4.set_ylabel('Learning Rate (log)')
        ax4.set_title('√âvolution du Learning Rate')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
    else:
        ax4.text(0.5, 0.5, 'Learning Rate non disponible',
                 horizontalalignment='center',
                 verticalalignment='center')
        ax4.set_title('Learning Rate')
    
    plt.tight_layout()
    os.makedirs('outputs', exist_ok=True)
    plt.savefig('outputs/lstm_training_history.png', dpi=300, bbox_inches='tight')
    print("‚úÖ Historique d'entra√Ænement sauvegard√©: outputs/lstm_training_history.png")
    
    return fig

def inverse_scale_predictions(scaled_data, scaler, n_features):
    """
    Inverse scaling des pr√©dictions
    """
    if len(scaled_data) == 0:
        return np.array([])
    
    dummy_array = np.zeros((len(scaled_data), n_features), dtype=np.float32)
    dummy_array[:, 0] = scaled_data.flatten()
    return scaler.inverse_transform(dummy_array)[:, 0]

def evaluate_lstm_model(model, X_test, y_test, scaler):
    """
    √âvalue le mod√®le LSTM sur l'ensemble de test
    """
    print("\nüìà √âvaluation du mod√®le LSTM...")
    
    # Essayer de charger le meilleur mod√®le d'abord
    best_model_path = 'models/lstm_best_model.keras'
    if os.path.exists(best_model_path):
        print(f"  üîÑ Chargement du meilleur mod√®le sauvegard√©: {best_model_path}")
        try:
            model = load_model(best_model_path)
            print("  ‚úÖ Meilleur mod√®le charg√© avec succ√®s")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Impossible de charger le meilleur mod√®le: {e}")
            print("  Utilisation du mod√®le actuel pour l'√©valuation...")
    else:
        print("  ‚ö†Ô∏è Fichier du meilleur mod√®le non trouv√©. Utilisation du mod√®le actuel.")
    
    # V√©rifier si X_test est vide
    if X_test is None or len(X_test) == 0:
        print("  ‚ö†Ô∏è X_test est vide ‚Äî √©valuation impossible.")
        return {'mae': float('nan'), 'rmse': float('nan'), 'mape': float('nan'),
                'y_true': np.array([]), 'y_pred': np.array([])}
    
    # Forcer numpy float32
    X_test = np.asarray(X_test, dtype=np.float32)
    y_test = np.asarray(y_test, dtype=np.float32).reshape(-1, 1)
    
    # Faire les pr√©dictions
    try:
        batch_size = min(32, max(1, len(X_test)))
        print(f"  üîÑ Pr√©diction sur {len(X_test)} √©chantillons (batch_size={batch_size})...")
        y_pred_scaled = model.predict(X_test, batch_size=batch_size, verbose=0)
        y_pred_scaled = np.asarray(y_pred_scaled).reshape(-1, 1)
        print(f"  ‚úÖ Pr√©diction termin√©e")
    except Exception as e:
        print(f"  ‚ùå √âchec de la pr√©diction: {e}")
        return {'mae': float('nan'), 'rmse': float('nan'), 'mape': float('nan'),
                'y_true': np.array([]), 'y_pred': np.array([])}
    
    # Inverse scaling
    n_features = scaler.n_features_in_
    y_pred = inverse_scale_predictions(y_pred_scaled, scaler, n_features)
    y_true = inverse_scale_predictions(y_test, scaler, n_features)
    
    # V√©rifier NaN / inf
    if np.isnan(y_pred).any() or np.isinf(y_pred).any():
        print("  ‚ö†Ô∏è y_pred contient des NaN ou inf")
        y_pred = np.nan_to_num(y_pred, nan=0.0, posinf=0.0, neginf=0.0)
    
    if np.isnan(y_true).any() or np.isinf(y_true).any():
        print("  ‚ö†Ô∏è y_true contient des NaN ou inf")
        y_true = np.nan_to_num(y_true, nan=0.0, posinf=0.0, neginf=0.0)
    
    # Calcul des m√©triques
    if len(y_true) > 0 and len(y_pred) > 0 and len(y_true) == len(y_pred):
        try:
            mae = mean_absolute_error(y_true, y_pred)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))
            
            # MAPE avec protection contre division par z√©ro
            non_zero_mask = np.abs(y_true) > 1e-10
            if np.sum(non_zero_mask) > 0:
                mape = np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / 
                                     y_true[non_zero_mask])) * 100
            else:
                mape = float('nan')
                
            print(f"\nüìä M√©triques d'√©valuation LSTM:")
            print(f"  MAE: {mae:.2f}")
            print(f"  RMSE: {rmse:.2f}")
            print(f"  MAPE: {mape:.2f}%")
            
        except Exception as e:
            print(f"  ‚ùå Erreur dans le calcul des m√©triques: {e}")
            mae, rmse, mape = float('nan'), float('nan'), float('nan')
    else:
        print(f"  ‚ö†Ô∏è Probl√®me avec les dimensions: y_true={len(y_true)}, y_pred={len(y_pred)}")
        mae, rmse, mape = float('nan'), float('nan'), float('nan')
    
    return {
        'mae': mae,
        'rmse': rmse,
        'mape': mape,
        'y_true': y_true.flatten(),
        'y_pred': y_pred.flatten()
    }

def plot_lstm_predictions(eval_results):
    """Visualise les pr√©dictions du LSTM"""
    os.makedirs('outputs', exist_ok=True)
    
    y_true = eval_results['y_true']
    y_pred = eval_results['y_pred']
    
    # V√©rifier si les donn√©es sont vides
    if len(y_true) == 0 or len(y_pred) == 0:
        print("  ‚ö†Ô∏è Pas de donn√©es pour les graphiques de pr√©diction")
        
        # Cr√©er un graphique simple pour indiquer l'absence de donn√©es
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.text(0.5, 0.5, 'Aucune donn√©e de test disponible\npour les pr√©dictions',
                horizontalalignment='center', verticalalignment='center',
                fontsize=14, color='red')
        ax.set_title('Graphique de pr√©diction indisponible')
        ax.axis('off')
        
        plt.tight_layout()
        plt.savefig('outputs/lstm_predictions.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("‚úÖ Graphique vide sauvegard√©: outputs/lstm_predictions.png")
        return
    
    # Si nous avons des donn√©es, cr√©er les 4 graphiques
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. Pr√©dictions vs r√©alit√©
    ax1 = axes[0, 0]
    ax1.plot(y_true, 'b-', label='Valeurs r√©elles', alpha=0.7, linewidth=1.5)
    ax1.plot(y_pred, 'r--', label='Pr√©dictions LSTM', alpha=0.8, linewidth=1.5)
    ax1.set_xlabel('√âchantillons de test')
    ax1.set_ylabel('Prix')
    ax1.set_title('Pr√©dictions LSTM vs R√©alit√©')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. Scatter plot
    ax2 = axes[0, 1]
    scatter = ax2.scatter(y_true, y_pred, alpha=0.6, edgecolors='k')
    
    # Ligne y=x (pr√©diction parfaite)
    min_val = min(y_true.min(), y_pred.min())
    max_val = max(y_true.max(), y_pred.max())
    ax2.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, linewidth=2)
    
    ax2.set_xlabel('Valeurs r√©elles')
    ax2.set_ylabel('Pr√©dictions')
    ax2.set_title(f'Corr√©lation pr√©dictions vs r√©alit√©\nMAE: {eval_results["mae"]:.2f}')
    ax2.grid(True, alpha=0.3)
    
    # 3. Erreurs de pr√©diction
    ax3 = axes[1, 0]
    errors = y_true - y_pred
    ax3.plot(errors, 'o-', alpha=0.7, markersize=3)
    ax3.axhline(y=0, color='r', linestyle='--', alpha=0.5, linewidth=2)
    ax3.set_xlabel('√âchantillons de test')
    ax3.set_ylabel('Erreur (r√©el - pr√©dit)')
    ax3.set_title('Erreurs de pr√©diction par √©chantillon')
    ax3.grid(True, alpha=0.3)
    
    # 4. Distribution des erreurs
    ax4 = axes[1, 1]
    n, bins, patches = ax4.hist(errors, bins=30, edgecolor='black', alpha=0.7)
    ax4.axvline(x=0, color='r', linestyle='--', alpha=0.5, linewidth=2)
    ax4.set_xlabel('Erreur')
    ax4.set_ylabel('Fr√©quence')
    ax4.set_title(f'Distribution des erreurs\nMAPE: {eval_results["mape"]:.2f}%')
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('outputs/lstm_predictions.png', dpi=300, bbox_inches='tight')
    print("‚úÖ Graphiques des pr√©dictions sauvegard√©s: outputs/lstm_predictions.png")
    
    return fig

def save_lstm_model(model, eval_results):
    """Sauvegarde le mod√®le LSTM et ses m√©triques"""
    print("\nüíæ Sauvegarde du mod√®le LSTM...")
    
    # Sauvegarde du mod√®le final en format .keras (recommand√©)
    model.save('models/lstm_model.keras')
    
    # Sauvegarde HDF5 pour compatibilit√© (avec suppression du warning)
    try:
        model.save('models/lstm_model.h5')
    except Exception as e:
        print(f"  ‚ö†Ô∏è Impossible de sauvegarder en HDF5: {e}")
    
    # Sauvegarde des m√©triques
    metrics = {
        'mae': float(eval_results['mae']) if not np.isnan(eval_results['mae']) else 'nan',
        'rmse': float(eval_results['rmse']) if not np.isnan(eval_results['rmse']) else 'nan',
        'mape': float(eval_results['mape']) if not np.isnan(eval_results['mape']) else 'nan',
        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    with open('models/lstm_metrics.json', 'w') as f:
        json.dump(metrics, f, indent=2)
    
    print("‚úÖ Mod√®le LSTM sauvegard√©: models/lstm_model.keras")
    if os.path.exists('models/lstm_model.h5'):
        print("‚úÖ Mod√®le HDF5 sauvegard√©: models/lstm_model.h5")
    print("‚úÖ M√©triques sauvegard√©es: models/lstm_metrics.json")
    
    return metrics

def predict_future_lstm(model, scaler, last_sequence, days_ahead=7, n_features=4):
    """
    Pr√©dit les prix futurs avec le mod√®le LSTM
    """
    print(f"\nüîÆ Pr√©diction des {days_ahead} prochains jours avec LSTM...")
    
    # V√©rifier si last_sequence est valide
    if last_sequence is None or len(last_sequence) == 0:
        print("  ‚ùå Derni√®re s√©quence non disponible pour les pr√©dictions futures")
        return []
    
    # Charger le meilleur mod√®le si disponible
    best_model_path = 'models/lstm_best_model.keras'
    if os.path.exists(best_model_path):
        try:
            model = load_model(best_model_path)
            print("  ‚úÖ Utilisation du meilleur mod√®le pour les pr√©dictions futures")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Impossible de charger le meilleur mod√®le: {e}")
            print("  Utilisation du mod√®le actuel")
    
    predictions = []
    current_sequence = last_sequence.copy()
    
    for day in range(days_ahead):
        # Pr√©diction pour le prochain jour
        pred_scaled = model.predict(current_sequence.reshape(1, -1, n_features), verbose=0)
        
        # Inverse scaling
        dummy_array = np.zeros((1, n_features))
        dummy_array[0, 0] = pred_scaled[0, 0]
        pred_price = scaler.inverse_transform(dummy_array)[0, 0]
        
        # Ajout √† la s√©quence pour la pr√©diction suivante
        new_row = current_sequence[-1].copy()
        new_row[0] = pred_scaled[0, 0]  # Mise √† jour du prix dans la s√©quence
        
        current_sequence = np.vstack([current_sequence[1:], new_row])
        
        # Calcul des dates
        prediction_date = (datetime.now() + timedelta(days=day+1)).strftime('%Y-%m-%d')
        
        predictions.append({
            'date': prediction_date,
            'predicted_price': round(float(pred_price), 2),
            'confidence': max(50, 95 - (day * 5))  # Confiance d√©croissante mais minimum 50%
        })
    
    # Sauvegarde des pr√©dictions
    os.makedirs('outputs', exist_ok=True)
    with open('outputs/lstm_predictions.json', 'w') as f:
        json.dump(predictions, f, indent=2)
    
    print(f"‚úÖ Pr√©dictions LSTM sauvegard√©es: outputs/lstm_predictions.json")
    
    return predictions

def print_summary(metrics, future_predictions):
    """Affiche un r√©sum√© format√© des r√©sultats"""
    print("\n" + "="*50)
    print(" R√âSUM√â DU MOD√àLE LSTM")
    print("="*50)
    
    print(f"üìÖ Date d'entra√Ænement: {metrics.get('training_date', 'N/A')}")
    print(f"üìä MAE: {metrics.get('mae', 'nan'):.2f}" if isinstance(metrics.get('mae'), (int, float)) else f"üìä MAE: {metrics.get('mae', 'nan')}")
    print(f"üìä RMSE: {metrics.get('rmse', 'nan'):.2f}" if isinstance(metrics.get('rmse'), (int, float)) else f"üìä RMSE: {metrics.get('rmse', 'nan')}")
    print(f"üìä MAPE: {metrics.get('mape', 'nan'):.2f}%" if isinstance(metrics.get('mape'), (int, float)) else f"üìä MAPE: {metrics.get('mape', 'nan')}%")
    
    if future_predictions:
        print(f"\nüîÆ Pr√©dictions pour les 7 prochains jours:")
        for pred in future_predictions:
            print(f"  üìÖ {pred['date']}: ${pred['predicted_price']:.2f} (confiance: {pred['confidence']}%)")
    else:
        print("\n‚ö†Ô∏è Aucune pr√©diction future disponible.")

def main():
    """Pipeline principal LSTM"""
    
    print("="*60)
    print("     D√âMARRAGE DU PIPELINE LSTM")
    print("="*60)
    
    # Cr√©ation des dossiers
    os.makedirs('outputs', exist_ok=True)
    os.makedirs('models', exist_ok=True)
    
    try:
        # 1. Chargement des donn√©es
        X_seq, y_seq, X_val_seq, y_val_seq, X_test_seq, y_test_seq = load_prepared_data()
        
        # V√©rifier que nous avons des donn√©es d'entra√Ænement
        if len(X_seq) == 0:
            raise ValueError("‚ùå Aucune donn√©e d'entra√Ænement disponible!")
        
        print(f"\n‚úÖ Donn√©es charg√©es avec succ√®s")
        
        # 2. Construction du mod√®le
        input_shape = (X_seq.shape[1], X_seq.shape[2])
        print(f"üìê Input shape: {input_shape}")
        model = build_lstm_model(input_shape, units=64, dropout_rate=0.2)
        
        # 3. Entra√Ænement
        print("\n" + "="*60)
        print("     PHASE D'ENTRA√éNEMENT")
        print("="*60)
        history, model = train_lstm_model(
            model, X_seq, y_seq, X_val_seq, y_val_seq,
            epochs=100, batch_size=32
        )
        
        # 4. Visualisation de l'entra√Ænement
        plot_training_history(history)
        
        # 5. √âvaluation
        print("\n" + "="*60)
        print("     PHASE D'√âVALUATION")
        print("="*60)
        
        # Charger le scaler - CORRECTION ICI
        scaler = None
        if os.path.exists('models/scaler.pkl'):
            scaler = joblib.load('models/scaler.pkl')
            print("   ‚úÖ Scaler charg√© depuis models/scaler.pkl")
        else:
            print("‚ùå Fichier scaler.pkl introuvable!")
            print("   Tentative de cr√©ation d'un scaler par d√©faut...")
            
            # Importer ici pour √©viter l'erreur de variable locale
            from sklearn.preprocessing import StandardScaler
            
            scaler = StandardScaler()
            # Fit avec quelques donn√©es factices bas√©es sur les donn√©es d'entra√Ænement
            if len(X_seq) > 0:
                # Cr√©er des donn√©es factices avec la m√™me forme
                dummy_data = np.random.randn(100, X_seq.shape[2])
                scaler.fit(dummy_data)
                print("   ‚úÖ Scaler par d√©faut cr√©√©")
            else:
                print("   ‚ùå Impossible de cr√©er un scaler - pas de donn√©es d'entra√Ænement")
                # Cr√©er un scaler vide
                scaler = StandardScaler()
                # Fit avec des donn√©es tr√®s simples
                scaler.fit(np.array([[0, 0, 0, 0]]))
                print("   ‚ö†Ô∏è Scaler tr√®s simple cr√©√© pour √©viter l'erreur")
            
            # Sauvegarder le scaler
            joblib.dump(scaler, 'models/scaler.pkl')
            print("   ‚úÖ Scaler sauvegard√© dans models/scaler.pkl")
        
        # √âvaluer le mod√®le
        eval_results = evaluate_lstm_model(model, X_test_seq, y_test_seq, scaler)
        
        # 6. Visualisation des pr√©dictions
        plot_lstm_predictions(eval_results)
        
        # 7. Sauvegarde
        metrics = save_lstm_model(model, eval_results)
        
        # 8. Pr√©diction future
        print("\n" + "="*60)
        print("     PR√âDICTIONS FUTURES")
        print("="*60)
        
        if X_test_seq is None or len(X_test_seq) == 0:
            print("‚ö†Ô∏è Aucune donn√©e de test disponible pour la pr√©diction future.")
            print("   Utilisation des derni√®res donn√©es d'entra√Ænement...")
            
            if len(X_seq) > 0:
                last_sequence = X_seq[-1]
                n_features = X_seq.shape[2]
                future_predictions = predict_future_lstm(
                    model, scaler, last_sequence, days_ahead=7, n_features=n_features
                )
            else:
                print("   ‚ùå Impossible - pas de donn√©es d'entra√Ænement non plus")
                future_predictions = []
        else:
            last_sequence = X_test_seq[-1]
            n_features = X_seq.shape[2]
            future_predictions = predict_future_lstm(
                model, scaler, last_sequence, days_ahead=7, n_features=n_features
            )
        
        # Afficher le r√©sum√©
        print_summary(metrics, future_predictions)
        
    except FileNotFoundError as e:
        print(f"\n‚ùå Erreur: {e}")
        print("Veuillez d'abord ex√©cuter le script de pr√©paration des donn√©es.")
        return None, None, None
    except ValueError as e:
        print(f"\n‚ùå Erreur: {e}")
        return None, None, None
    except Exception as e:
        print(f"\n‚ùå Erreur dans le pipeline LSTM: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None
    
    print("\n" + "="*60)
    print("     PIPELINE LSTM TERMIN√â")
    print("="*60)
    
    return model, metrics, future_predictions

if __name__ == "__main__":
    model, metrics, predictions = main()